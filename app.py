import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import re  # å¼•å…¥ re æ¨¡çµ„
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_recall_curve, average_precision_score,
    roc_curve, auc
)
from sklearn.preprocessing import LabelEncoder
from set_bg import set_bg_image
import joblib
import os



# -------------------- é é¢è¨­å®š --------------------
PAGE_TITLE = "AI è©é¨™ç°¡è¨Šåµæ¸¬å™¨"
PAGE_ICON = "ğŸ“©"
st.set_page_config(page_title=PAGE_TITLE, page_icon=PAGE_ICON)

set_bg_image("1.jpg")  # æ›¿æ›æˆæ‚¨åœ–ç‰‡çš„è·¯å¾‘

st.markdown(f'<h1 class="glow">{PAGE_ICON} {PAGE_TITLE}</h1>', unsafe_allow_html=True)
st.markdown("""
<div style='font-family:DFKai-SB; font-size:20px;'>
ğŸ“© è«‹è¼¸å…¥ç°¡è¨Šå…§å®¹ï¼Œæˆ‘å€‘æœƒç”¨ AI æ¨¡å‹å”åŠ©ä½ è¾¨è­˜æ˜¯å¦ç‚ºè©é¨™è¨Šæ¯ï¼ˆSpamï¼‰ã€‚
</div>
""", unsafe_allow_html=True)

# -------------------- è³‡æ–™è¼‰å…¥ --------------------
@st.cache_data
def load_data():
    # å‡è¨­è³‡æ–™é›†ç‚ºCSVæ ¼å¼
    df = pd.read_csv("1000000.csv")
    return df

df = load_data()
st.write(f"ğŸ“Š è³‡æ–™é›†å·²è¼‰å…¥ï¼š{len(df):,} ç­†")

# -------------------- æ–‡å­—é è™•ç† --------------------
def preprocess_text(text):
    text = text.lower()  # å°å¯«åŒ–
    text = re.sub(r"[^\w\s]", "", text)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
    return text

df['processed_message'] = df['message'].apply(preprocess_text)

# -------------------- ç›®æ¨™èˆ‡ç‰¹å¾µ --------------------
le = LabelEncoder()
df['label_num'] = le.fit_transform(df['label'])  # scam=1, normal=0

X = df['processed_message']
y = df['label_num']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# -------------------- æ¨¡å‹å„²å­˜èˆ‡é¸æ“‡ --------------------
MODEL_PATH = "spam_model.pkl"

def save_model(model):
    with open(MODEL_PATH, 'wb') as f:
        joblib.dump(model, f)

def load_model():
    if os.path.exists(MODEL_PATH):
        with open(MODEL_PATH, 'rb') as f:
            model = joblib.load(f)
            # æª¢æŸ¥æ¨¡å‹æ˜¯å¦ç‚ºæ­£ç¢ºçš„é¡å‹
            if hasattr(model, 'predict') and callable(getattr(model, 'predict')):
                return model
            else:
                st.warning("âš ï¸ é€™ä¸æ˜¯ä¸€å€‹æœ‰æ•ˆçš„æ¨¡å‹æ–‡ä»¶")
                return None
    return None


# é è¨­è¼‰å…¥æ¨¡å‹ç‚º MNB
model = load_model()

# -------------------- æ¨¡å‹é¸æ“‡ --------------------
model_option = st.selectbox("é¸æ“‡æ¨¡å‹", ["Naive Bayes (MNB)", "SVM"])

if model is None or st.button("è¨“ç·´æ¨¡å‹"):
    if model_option == "Naive Bayes (MNB)":
        model = MultinomialNB()
    elif model_option == "SVM":
        model = SVC(probability=True)
    
    model.fit(X_train_tfidf, y_train)
    save_model(model)
    st.success(f"æ¨¡å‹è¨“ç·´æˆåŠŸï¼ä½¿ç”¨ {model_option} æ¨¡å‹é€²è¡Œè¨“ç·´ã€‚")

# -------------------- é æ¸¬å‡½æ•¸ --------------------
def predict_message(msg):
    tfidf_msg = vectorizer.transform([msg])
    pred = model.predict(tfidf_msg)[0]
    prob = model.predict_proba(tfidf_msg)[0][pred]
    label_name = le.inverse_transform([pred])[0]
    return ("è©é¨™ç°¡è¨Š (Scam)" if label_name == "scam" else "æ­£å¸¸ç°¡è¨Š (Normal)"), round(prob * 100, 2)

# -------------------- ä½¿ç”¨è€…è¼¸å…¥å€ --------------------
user_input = st.text_area("è«‹è¼¸å…¥ç°¡è¨Šå…§å®¹ï¼š", height=100)

if st.button("ğŸ” é–‹å§‹åˆ†æ"):
    if user_input.strip() == "":
        st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ç°¡è¨Šå…§å®¹")
    else:
        result, confidence = predict_message(user_input)
        st.success(f"ğŸ“Œ é æ¸¬çµæœï¼š{result}ï¼ˆä¿¡å¿ƒåˆ†æ•¸ï¼š{confidence}%ï¼‰")

# -------------------- è©•ä¼°å ±å‘Š --------------------
with st.expander("ğŸ” é¡¯ç¤ºå®Œæ•´è©•ä¼°å ±å‘Š"):
    y_pred = model.predict(X_test_tfidf)
    acc = accuracy_score(y_test, y_pred)
    st.metric(label="ğŸ¯ æ¸¬è©¦é›†æº–ç¢ºç‡", value=f"{acc * 100:.2f}%")

    report = classification_report(y_test, y_pred, output_dict=True, target_names=le.classes_)
    st.subheader("ğŸ“„ Classification Report")
    st.dataframe(report)

    # æ··æ·†çŸ©é™£ï¼ˆæ•¸å€¼ï¼‰
    cm = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(cm,
                         index=[f"å¯¦éš›:{cls}" for cls in le.classes_],
                         columns=[f"é æ¸¬:{cls}" for cls in le.classes_])
    st.subheader("ğŸ”¢ æ··æ·†çŸ©é™£ï¼ˆæ•¸å€¼ï¼‰")
    st.dataframe(cm_df)

    # æ··æ·†çŸ©é™£ï¼ˆåœ–å½¢ï¼‰
    fig, ax = plt.subplots()
    im = ax.imshow(cm, cmap="Blues")
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, cm[i, j], ha="center", va="center")
    ax.set_xticks(range(len(le.classes_)))
    ax.set_xticklabels(le.classes_, rotation=45, ha="right")
    ax.set_yticks(range(len(le.classes_)))
    ax.set_yticklabels(le.classes_)
    ax.set_xlabel("é æ¸¬æ¨™ç±¤")
    ax.set_ylabel("å¯¦éš›æ¨™ç±¤")
    ax.set_title("Confusion Matrix")
    st.subheader("ğŸ¨ æ··æ·†çŸ©é™£ï¼ˆè¦–è¦ºåŒ–ï¼‰")
    st.pyplot(fig)

    # é¡åˆ¥åˆ†ä½ˆæŠ˜ç·šåœ–
    st.subheader("ğŸ“ˆ ç°¡è¨Šé¡åˆ¥åˆ†ä½ˆæŠ˜ç·šåœ–")
    label_counts = df['label'].value_counts().sort_index()
    fig2, ax2 = plt.subplots()
    ax2.plot(label_counts.index, label_counts.values, marker='o', linestyle='-', color='darkorange')
    ax2.set_title("Scam / Normal æ•¸é‡è¶¨å‹¢")
    ax2.set_xlabel("é¡åˆ¥")
    ax2.set_ylabel("ç°¡è¨Šæ•¸é‡")
    ax2.grid(True)
    st.pyplot(fig2)

    # ROC æ›²ç·š
    st.subheader("ğŸ“‰ æ¨¡å‹æ•ˆèƒ½ ROC æ›²ç·š")
    y_scores = model.predict_proba(X_test_tfidf)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_scores)
    roc_auc = auc(fpr, tpr)

    fig3, ax3 = plt.subplots()
    ax3.plot(fpr, tpr, color='darkblue', lw=2, label=f'ROC æ›²ç·š (AUC = {roc_auc:.2f})')
    ax3.plot([0, 1], [0, 1], color='gray', linestyle='--')
    ax3.set_xlim([0.0, 1.0])
    ax3.set_ylim([0.0, 1.05])
    ax3.set_xlabel('False Positive Rate (å‡é™½æ€§ç‡)')
    ax3.set_ylabel('True Positive Rate (çœŸé™½æ€§ç‡)')
    ax3.set_title('ROC Curve')
    ax3.legend(loc="lower right")
    ax3.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig3)

    # PR æ›²ç·š
    st.subheader("ğŸ“ˆ Precision-Recall æ›²ç·šï¼ˆPR Curveï¼‰")
    precision, recall, _ = precision_recall_curve(y_test, y_scores)
    avg_precision = average_precision_score(y_test, y_scores)

    fig_pr, ax_pr = plt.subplots()
    ax_pr.plot(recall, precision, label=f'Average Precision = {avg_precision:.2f}', color='darkorange')
    ax_pr.set_xlabel('Recall')
    ax_pr.set_ylabel('Precision')
    ax_pr.set_title('Precision-Recall Curve')
    ax_pr.legend()
    ax_pr.grid(True, linestyle='--', alpha=0.5)
    st.pyplot(fig_pr)

     # === mAPï¼ˆMean Average Precisionï¼‰ ===
    st.subheader("ğŸ“Š mAPï¼ˆå„é¡åˆ¥ PR æ›²ç·šï¼‰")

    from sklearn.preprocessing import label_binarize
    from sklearn.metrics import precision_recall_curve, average_precision_score

    y_score_all = model.predict_proba(X_test_tfidf)
    y_test_bin = label_binarize(y_test, classes=list(le.transform(le.classes_)))

    # äºŒå…ƒåˆ†é¡æ™‚éœ€ reshape
    if y_test_bin.ndim == 1:
        y_test_bin = y_test_bin.reshape(-1, 1)

    if y_score_all.shape[1] == y_test_bin.shape[1]:  # ç¢ºä¿ç¶­åº¦å°æ‡‰
        ap_dict = {}
        fig_map, ax_map = plt.subplots()
        for i, class_name in enumerate(le.classes_):
            precision, recall, _ = precision_recall_curve(y_test_bin[:, i], y_score_all[:, i])
            ap = average_precision_score(y_test_bin[:, i], y_score_all[:, i])
            ap_dict[class_name] = ap
            ax_map.plot(recall, precision, lw=2, label=f'{class_name} (AP={ap:.2f})')

        mean_ap = sum(ap_dict.values()) / len(ap_dict)
        ax_map.set_title(f"Mean Average Precision (mAP) = {mean_ap:.2f}")
        ax_map.set_xlabel("Recall")
        ax_map.set_ylabel("Precision")
        ax_map.legend(loc="lower left")
        ax_map.grid(True, linestyle='--', alpha=0.5)
        st.pyplot(fig_map)
    else:
        st.warning("âš ï¸ åˆ†é¡æ•¸é‡ä¸ç¬¦ï¼Œç„¡æ³•ç”¢ç”Ÿ mAP æ›²ç·š")